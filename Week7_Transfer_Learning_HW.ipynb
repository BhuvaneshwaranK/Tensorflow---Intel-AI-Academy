{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import itertools as it\n",
    "\n",
    "import helpers_07\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal this week is to apply a *previously trained network* (that was trained on the ILSVRC dataset), modify it slightly, and with only minimal retraining on a new dataset (called HamsterHare), use it to predict on the new task.  Let's go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Different Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per usual, we've hidden the complexity of grabbing the data.  Because the dataset is a bit bigger, for now, we only return paths to files (and not full images as a NumPy array).  We'll deal with that more in a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers_07.download_hh(\"data/hh\")\n",
    "# note:  label=1 means hare; label=0 means hamster\n",
    "readable_hh_labels = {1:\"hare\", 0:\"hamster\"}\n",
    "(train_files, train_labels, \n",
    " test_files, test_labels) = helpers_07.train_test_split_hh_filenames(test_pct=.3)\n",
    "print(\"\\n\".join(str(t) for t in train_files[:5]))\n",
    "print(\"\\n\".join(str(t) for t in train_labels[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we're dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imread\n",
    "img = imread(train_files[0], mode=\"RGB\")[:,:,:3]\n",
    "plt.imshow(img)\n",
    "plt.title(readable_hh_labels[train_labels[0]])\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Re-)Loading a Model and Accessing Named Model Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Named Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a few minutes, we are going to reload the AlexNet we built last week.  When we do so, we will have  agrat network, but we will have no variables referencing the Tensors and Operations inside of it.  We need to deal with that, so at minimum we can feed it data.  We'll even go beyond that:  we'll add Operations to the network so we can retrain portions of it.\n",
    "\n",
    "To get started, let's look at a simpler example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph = tf.Graph()\n",
    "with test_graph.as_default():\n",
    "    a = tf.constant(3,   name=\"constant_a\")\n",
    "    b = tf.constant(4,   name=\"constant_b\")\n",
    "    c = tf.multiply(a,b, name=\"mul_for_c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access operations.  A few points:\n",
    "  * ops are the \"nodes\" in the graph \n",
    "  * they are operations that perform computation\n",
    "  * op name is same as we passed to name="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting an Operation\")\n",
    "print(test_graph.get_operation_by_name('mul_for_c'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can access tensors.  A few points:\n",
    "  * tensors are the data or edges in the Graph\n",
    "  * they often are the result of an Operation\n",
    "  * tensor name is the `op:<number>` \n",
    "  * many ops have only one output (the data we want), so the number is often 0\n",
    "  * some ops have multiple outputs, to the numbers go 0,1,2, for diff output tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting a Tensor:\")\n",
    "new_c_ref = test_graph.get_tensor_by_name('mul_for_c:0')\n",
    "print(c)\n",
    "print(new_c_ref)\n",
    "print(c is new_c_ref) # aka, refer to -same- object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's bring back in the AlexNet we (possibly struggled) to create last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder graph to \"rehydrate\" our freeze-dried AlexNet\n",
    "old_alex_graph = tf.Graph()\n",
    "with old_alex_graph.as_default():\n",
    "    # importing the graph will populate new_alex_graph\n",
    "    saver = tf.train.import_meta_graph(\"../week_06/saved_models/alexnet.meta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can use some `get_*_by_name` methods to extract out tensors and operations.  Note, we have to know these ahead of time (but, see below!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the form is scope/name= ; for output tensor, we can tack on :0\n",
    "print(old_alex_graph.get_tensor_by_name('inputs/images:0'), \"\\n\",\n",
    "      old_alex_graph.get_operation_by_name('inputs/images'), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have sort of an idealized scenario: we made the graph last week.  So, we know (or we could go back to our old code an lookup) the names of the tensors and operations.  But, what if (1) someone else gave us the graph, (2) we lost our old code, (3) we needed to programmatically get the names of tensors/operations.  What would we do?  Fortunately, this is a solved problem.  We use `get_operations` as in `old_alex_graph.get_operations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(str(op.name) for op in old_alex_graph.get_operations()[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way we'll actually use this is to grab the specific tensors we need to work with in our new/transfered use of our AlexNet.  Namely, we need the inputs and we need whatever \"end point\" we are going to cut off the old AlexNet and move to our new AlexNet.  We're just going to cut out the last layer (`fc8` from last time).  So, we'll pipe `fc7` somewhere else.  More to come on that shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get references (Python variables) that refer \n",
    "# to the named elements we need to access\n",
    "inputs = old_alex_graph.get_tensor_by_name('inputs/images:0')\n",
    "fc7    = old_alex_graph.get_tensor_by_name(\"alexnet/fully_connected_1/fc7:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if you can pickout the operations in the `fully_connected` name scope from the old graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Retraining Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our original AlexNet model didn't have any training component (we populated its weights directly from NumPy arrays), we have some work to do, if we want to add training capabilities.  Here's a template from our older trainable models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look inside the following code and try to build up a model that resuses as much as possible from the prior model.  Here's was out outline of steps from the slides:\n",
    "\n",
    "  1. Get handle to output from second-to-last layer\n",
    "  2. Create a new fully connected layer\n",
    "    * number of neurons equal to the number of output classes)\n",
    "  3. Create new softmax cross-entropy loss\n",
    "  4. Create a training op to minimize the new loss\n",
    "    * Set var_list parameter to be just the new layer variables\n",
    "  5. Train with new data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferedAlexNet:\n",
    "    def __init__(s, init_graph):\n",
    "        with init_graph.as_default():\n",
    "            #\n",
    "            # The original AlexNet from last week didn't have:\n",
    "            #      labels, loss, training\n",
    "            # Also, it's prediction was structured for 1000 output classes\n",
    "            # \n",
    "            # Since we passed in init_graph above, we are working *with* that\n",
    "            # old AlexNet.  But you can add to it.  For example: here we are *adding*\n",
    "            # a labels placeholder to the original model:\n",
    "            with tf.name_scope('inputs'):\n",
    "                s.labels = tf.placeholder(tf.int32, shape=[None], name='labels')\n",
    "\n",
    "            #\n",
    "            # revisit one of your older models, and add in the remaining pieces:\n",
    "            # learning_rate, loss, global_step, training, a new prediction system, etc.\n",
    "            # \n",
    "            # you'll also need a new final layer to replace the fc8 layer from last time\n",
    "            # you can use helper_07.fully_connected_xavier_relu_layer\n",
    "            # to replace it ...\n",
    "            #\n",
    "            \n",
    "            #\n",
    "            # FILL ME IN\n",
    "            # \n",
    "\n",
    "            init = tf.global_variables_initializer()\n",
    "        s.session = tf.Session(graph=init_graph)\n",
    "        s.session.run(init)\n",
    "\n",
    "    def fit(s, train_dict):\n",
    "        tr_loss, step, tr_acc, _ = s.session.run([s.loss, s.inc_step, s.pred_accuracy, s.train], \n",
    "                                                 feed_dict=train_dict)\n",
    "        return tr_loss, step, tr_acc\n",
    "    \n",
    "    def predict(s, test_dict):\n",
    "        ct_correct, preds = s.session.run([s.pred_correct, s.prediction], \n",
    "                                          feed_dict=test_dict)\n",
    "        return ct_correct, preds    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code adds one nice twist.  If you look at lines 31 and 37 (use Control-m followed by l - little 'ell' in the cell to get line numbers), you'll see that we setup a way to only optimize on the selected variables:  in this case, the variables from our new end layer.  This saves a ton of time (fewer parameters to work with) -and- it prevents us from losing the work done in the prior (very long/large) training steps (i.e., the work done before we even got our old AlexNet weights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferedAlexNet:\n",
    "    def __init__(s, init_graph, num_tgt_classes):\n",
    "        with init_graph.as_default():\n",
    "            with tf.name_scope('inputs'):\n",
    "                # have input placeholder from original graph\n",
    "                s.labels = tf.placeholder(tf.int32, shape=[None], name='labels')\n",
    "\n",
    "            with tf.name_scope('hyperparams'):\n",
    "                s.learning_rate = tf.placeholder(tf.float32, name='learning_rate')                \n",
    "            \n",
    "            s.one_hot_labels = tf.one_hot(s.labels, 2) # , dtype=tf.float32) \n",
    "            \n",
    "            #\n",
    "            # we're going to rewire the outputs from the old fc7 to our new layer\n",
    "            #\n",
    "            orig_fc7    = init_graph.get_tensor_by_name(\"alexnet/fully_connected_1/fc7:0\")\n",
    "            with tf.name_scope('new_top_layer'):\n",
    "                # the old fc8 (which we are replacing) had 1000 nodes for 1000 classes\n",
    "                s.logits = helpers_07.fully_connected_xavier_relu_layer(orig_fc7, num_tgt_classes) \n",
    "            \n",
    "            with tf.name_scope('loss'):\n",
    "                smce = tf.nn.softmax_cross_entropy_with_logits\n",
    "                s.loss = tf.reduce_mean(smce(logits=s.logits, labels=s.one_hot_labels),\n",
    "                                             name=\"loss\")\n",
    "\n",
    "            with tf.name_scope('global_step'):\n",
    "                global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "                s.inc_step = tf.assign_add(global_step, 1, name='inc_step')\n",
    "\n",
    "            # use to_train_vars = None to train on all trainable (including those from original)\n",
    "            to_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"new_top_layer\")\n",
    "            \n",
    "            with tf.name_scope('train'):\n",
    "                decayed_rate = tf.train.exponential_decay(s.learning_rate, global_step,\n",
    "                                                          600, 0.998, True)\n",
    "                momopt = tf.train.MomentumOptimizer\n",
    "                s.train = momopt(decayed_rate, 0.9).minimize(s.loss, var_list=to_train_vars)\n",
    "            \n",
    "            # there is a prediction namescope in the original model\n",
    "            # note, that the variable assignments here are attributes of this class\n",
    "            # and refer to distinct operations compared to the original model\n",
    "            with tf.name_scope('new_prediction'):\n",
    "                s.softmax    = tf.nn.softmax(s.logits, name=\"softmax\")\n",
    "                s.prediction = tf.cast(tf.arg_max(s.softmax, 1), tf.int32)\n",
    "                \n",
    "                s.pred_correct  = tf.equal(s.labels, s.prediction)\n",
    "                s.pred_accuracy = tf.reduce_mean(tf.cast(s.pred_correct, tf.float32))    \n",
    "            \n",
    "            init = tf.global_variables_initializer()\n",
    "        s.session = tf.Session(graph=init_graph)\n",
    "        s.session.run(init)\n",
    "\n",
    "    def fit(s, train_dict):\n",
    "        tr_loss, step, tr_acc, _ = s.session.run([s.loss, s.inc_step, s.pred_accuracy, s.train], \n",
    "                                                 feed_dict=train_dict)\n",
    "        return tr_loss, step, tr_acc\n",
    "    \n",
    "    def predict(s, test_dict):\n",
    "        ct_correct, preds = s.session.run([s.pred_correct, s.prediction], \n",
    "                                          feed_dict=test_dict)\n",
    "        return ct_correct, preds    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's put this all together and retrain with some new data.  I'm going to show a few options that demonstrate different techniques you might need.  One issue we pushed under the hood, was that of the input shape. In TensorFlow, single batches of images must all be the same size.  Even if the AlexNet we built can rescale images to 227 by 227, the inputs all need to be of one, common size.  Even worse, our Hamster Hare images are all varying sizes.   To show off an alternative use of TensorFlow, here is a set of helpers to rescale images (one image at a time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TF_ReadAndScale:\n",
    "    'rescale images to a common size'\n",
    "    def __init__(self, img_size=[227, 227]):\n",
    "        self.img_size = img_size\n",
    "        ras_graph = tf.Graph()\n",
    "        with ras_graph.as_default():\n",
    "            self.img_path = tf.placeholder(tf.string)\n",
    "            raw_data  = tf.read_file(self.img_path)\n",
    "            jpg_image = tf.image.decode_jpeg(raw_data, channels=3)\n",
    "            self.scaled_img = tf.image.resize_images(jpg_image, img_size)\n",
    "        self.session = tf.Session(graph=ras_graph)\n",
    "        \n",
    "    def scale(self, img_path):\n",
    "        return self.session.run(self.scaled_img, feed_dict={self.img_path:img_path})\n",
    "\n",
    "def image_files_into_array(img_file_lst, dtype=np.uint8, limit=None):\n",
    "    'take a list of filenames; return an array of images'\n",
    "    scaler = TF_ReadAndScale()\n",
    "\n",
    "    num_images = len(img_file_lst)\n",
    "    img_array_shape = [num_images] + scaler.img_size + [3]\n",
    "    img_array = np.empty(img_array_shape, dtype=dtype)\n",
    "    \n",
    "    for tf, img_home in it.islice(zip(img_file_lst, img_array), limit):\n",
    "        img_home[:] = scaler.scale(tf)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that out of the way, let's build our model and get set to feed it new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# danger, rerunning will modify a modified model\n",
    "# b/c the reruns share the old_alex_graph\n",
    "# and it is updating through the reference\n",
    "new_alex = TransferedAlexNet(old_alex_graph, num_tgt_classes=2) \n",
    "inputs   = old_alex_graph.get_tensor_by_name('inputs/images:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to save ourselves a lot of processing time (at the cost of some memory usage) but rescaling all of the images before we pass them for training.  See below for an alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can set a limit here to either use all the data (limit = None)\n",
    "# or, set to a small integer if you want to debug/time test (not for production)\n",
    "limit = None # use all of a batch   \n",
    "# limit = 10     # use just 10 images per batch (completely ignore remainder)\n",
    "batch_size = 32  # you can scale this up, if you want more images through your net at once\n",
    "\n",
    "# way above, we did:\n",
    "# (train_files, train_labels, \n",
    "#  test_files, test_labels) = helpers_07.train_test_split_hh_filenames(test_pct=.3)\n",
    "# this load all of the images into memory; could be a problem on some machines\n",
    "img_array = image_files_into_array(train_files, dtype=np.float32)\n",
    "lbl_array = np.array(train_labels)\n",
    "\n",
    "for epoch in range(5):\n",
    "    start = time.time()\n",
    "    batcher = helpers_07.array_batches(img_array, lbl_array, batch_size)\n",
    "    for image_batch, label_batch in it.islice(batcher, limit):\n",
    "        train_dict = {inputs : image_batch, \n",
    "                      new_alex.labels : label_batch, \n",
    "                      new_alex.learning_rate : 0.05}\n",
    "        tr_loss, step, tr_acc = new_alex.fit(train_dict)\n",
    "    end = time.time()\n",
    "    info_update = \"Epoch: {:2d} Step: {:5d} Loss: {:8.2f} Acc: {:5.2f} Time: {:5.2f}\"\n",
    "    print(info_update.format(epoch, step, tr_loss, tr_acc, (end - start) / 60.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an alternative that shows off what you might have to do if you have large data and/or small physical memory size.  Instead of loading all the images into memory at once, we simply load them \"on demand\" as needed by the batches.  Note, the specific loop below also means that we rescale the images every time they are opened.  We could rescale and save and then reopen the saved version, if we wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_it():\n",
    "    scaler = TF_ReadAndScale()\n",
    "    for epoch in range(5):\n",
    "        start = time.time()\n",
    "        batcher = helpers_07.list_batches(train_files, train_labels, 32)\n",
    "        for file_batch, label_batch in it.islice(batcher, 10):\n",
    "            image_batch = [scaler.scale(a_file) for a_file in file_batch]\n",
    "            train_dict = {inputs : image_batch, \n",
    "                          new_alex.labels : label_batch, \n",
    "                          new_alex.learning_rate : 0.05}\n",
    "            tr_loss, step, tr_acc = new_alex.fit(train_dict)\n",
    "        end = time.time()\n",
    "        info_update = \"Epoch: {:2d} Step: {:5d} Loss: {:8.2f} Acc: {:5.2f} Time: {:5.2f}\"\n",
    "        print(info_update.format(epoch, step, tr_loss, tr_acc, (end - start) / 60.0))\n",
    "# do_it() # disabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to run this once to see the difference in running times compared to the above \"scale them all once\" method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `.predict` method we gave `TransferedAlexNet`, write some code to evaluate it on a test set.  Remember, we need to scale the test images before they are fed to our model.  Here's a template (that needs several modification to be used) from the Week 04 notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_correct = 0\n",
    "#for batch_data, batch_labels in batches(test_data, test_labels, 200):\n",
    "#    test_dict = {}\n",
    "#    correctness, curr_preds = model.predict(test_dict)\n",
    "#    total_correct += correctness.sum()\n",
    "#print(total_correct / len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
