{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 01 - TensorFlow Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary construct in the TensorFlow API is the \"computation graph\", or just \"graph\" as we'll be calling it in this class. A computation graph is a useful way to illustrate the flow of data through multiple operations. Here's a basic example showing the graph for adding two numbers together:\n",
    "\n",
    "<img src=\"./images/01.png\" width=40%/>\n",
    "\n",
    "The arrows represent data flowing through through the graph (in this case the numbers 7, 3, and 10) while the nodes represent some form of computation (in this case addition).\n",
    "\n",
    "We can chain multiple of these computations together to form a more complex transformation of the data:\n",
    "\n",
    "<img src=\"./images/02.png\" width=60%/>\n",
    "\n",
    "Here, the numbers 3 and 7 are sent to an addition operation and a multiplication operation. The outputs of both of these are then sent to a subtraction operation. There are a few ways to illustrate the above operations.\n",
    "\n",
    "* We could show this as a one-liner math equation, using parentheses to show the order of operations:\n",
    "\n",
    "$$\n",
    "output = \\left( 3 + 7 \\right) - \\left( 3 \\times 7 \\right) = -11\n",
    "$$\n",
    "\n",
    "* We could also define the separate operations as mathematical functions:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "a(x, y) &= x + y \\\\\n",
    "b(x, y) &= x \\times y \\\\\n",
    "c(x, y) &= a(x, y) - b(x, y) \\\\ \\\\\n",
    "c(3, 7) &= a(3, 7) - b(3, 7) = -11\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "* Programmatically, the previous equations could be created with something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x, y):\n",
    "    return x + y\n",
    "   \n",
    "def multiply(x, y):\n",
    "    return x * y\n",
    "    \n",
    "def subtract(x, y):\n",
    "    return x - y\n",
    "    \n",
    "x = 3\n",
    "y = 7\n",
    "a = add(x, y)\n",
    "b = multiply(x, y)\n",
    "c = subtract(a, b)\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data isn't just one and done, either; it can be reused multiple times throughout the computation:\n",
    "\n",
    "<img src=\"./images/03.png\" width=70%/>\n",
    "\n",
    "This graph is similar to the previous model, but now we're reusing the 3 by adding it back in at the end. The code might look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 3\n",
    "y = 7\n",
    "a = add(x, y)\n",
    "b = multiply(x, y)\n",
    "c = subtract(a, b)\n",
    "d = add(c, x)\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My First TensorFlow Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental TensorFlow work flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pattern will be used again and again throughout the course. When working with TensorFlow, your code will effectively be divided into two parts:\n",
    "\n",
    "1. Define a graph which contains your model\n",
    "2. Run the graph.  Two special cases are:\n",
    "  * Train the model\n",
    "  * Test/predict using the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define a computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.placeholder creates an \"input\" node\n",
    "# we MUST give it value when we run our model\n",
    "# these can be data we want to learn from or \n",
    "# values of hyper-parameters for our model\n",
    "a = tf.placeholder(tf.int32, name=\"input_a\")\n",
    "b = tf.placeholder(tf.int32, name=\"input_b\")\n",
    "\n",
    "# tf.add creates an addition node\n",
    "c = tf.add(a, b, name=\"add\")\n",
    "\n",
    "# tf.multiply creates a multiplication node\n",
    "d = tf.multiply(a, b, name=\"multiply\")\n",
    "\n",
    "# Add up the results of the previous two nodes\n",
    "out = tf.add(c, d, name=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Create a \"feed_dict\" dictionary to define input values\n",
    "# Keys to dictionary are handles to our placeholders\n",
    "# Values to dictionary are values we'd like to feed in\n",
    "feed_dict = { a: 4, b: 3 }\n",
    "\n",
    "# Execute the graph using `sess.run()`, which takes two parameters:\n",
    "# - `fetches` lists which node(s) we'd like to receive as output\n",
    "# - `feed_dict` feeds in key-value pairs to input to various nodes\n",
    "# In this case, we pass in the Tensor `out` as our value for `fetches`,\n",
    "# which causes the value for out to be computed and returned\n",
    "result = sess.run(out, feed_dict=feed_dict)\n",
    "\n",
    "# Print the value of `out`\n",
    "print(\"({0}*{1}) + ({0}+{1}) = {2!s}\".format(feed_dict[a], feed_dict[b], result))\n",
    "\n",
    "# Close the session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Core API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our main TensorFlow objects are:\n",
    "\n",
    "  * `tf.Tensor`\n",
    "  * `tf.Operation`\n",
    "  * `tf.Graph`\n",
    "  * `tf.Session`\n",
    "  * `tf.Variable`\n",
    "\n",
    "We will introduce each of these below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Tensor` Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is a Tensor?\n",
    "\n",
    "Tensors, for our purposes, are $n$-dimensional matrices (or tables of numbers).\n",
    "  * a 0-dimensional tensor is a single number (or scalar)\n",
    "  * a 1-dimensional tensor is a vector, and \n",
    "  * a 2-dimensional tensor is a standard matrix. \n",
    "  \n",
    "Higher dimensional tensors are simply referred to as an *$n$-D tensor*.  Every value that is passed through a TensorFlow model is a `Tensor` object - the TensorFlow representation of a tensor.\n",
    "\n",
    "##### Defining tensors by hand\n",
    "\n",
    "You can define `Tensor` object values in two main ways:\n",
    "\n",
    "1. Native Python types\n",
    "2. NumPy arrays (recommended)\n",
    "\n",
    "Both of these can be automatically converted into TensorFlow `Tensor` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors from Native Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-D tensor (scalar)\n",
    "t_0d_py = 4\n",
    "\n",
    "# 1-D tensor (vector)\n",
    "t_1d_py = [1, 2, 3]\n",
    "\n",
    "# 2-D tensor (matrix)\n",
    "t_2d_py = [[1, 2], \n",
    "           [3, 4], \n",
    "           [5, 6]]\n",
    "\n",
    "# 3-D tensor\n",
    "t_3d_py = [[[0, 0], [0, 1], [0, 2]],\n",
    "           [[1, 0], [1, 1], [1, 2]],\n",
    "           [[2, 0], [2, 1], [2, 2]]]\n",
    "\n",
    "python_defined_tensors = [t_0d_py, t_1d_py, t_2d_py, t_3d_py]\n",
    "\n",
    "# tf.constant creates a tf.Tensor from a fixed value\n",
    "# you can read more here:\n",
    "#  https://www.tensorflow.org/api_docs/python/tf/constant\n",
    "for pdt in python_defined_tensors:\n",
    "    print(tf.constant(pdt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, we haven't *run* this constant tensor yet.  We've only defined it.  And, it knows a little bit about itself:  its shape.  We'll get into these details in just a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Arrays\n",
    "\n",
    "Pretty much the same as native Python, but with the `numpy.array` function wrapping it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-D tensor (scalar)\n",
    "t_0d_np = np.array(4, dtype=np.int32)\n",
    "\n",
    "# 1-D tensor (vector)\n",
    "t_1d_np = np.array([1, 2, 3], dtype=np.int64)\n",
    "\n",
    "# 2-D tensor (matrix)\n",
    "t_2d_np = np.array([[1, 2], \n",
    "                    [3, 4], \n",
    "                    [5, 6]],\n",
    "                   dtype=np.float32)\n",
    "\n",
    "# 3-D tensor\n",
    "t_3d_np = np.array([[[0, 0], [0, 1], [0, 2]],\n",
    "                    [[1, 0], [1, 1], [1, 2]],\n",
    "                    [[2, 0], [2, 1], [2, 2]]],\n",
    "                   dtype=np.int32)\n",
    "\n",
    "numpy_defined_tensors = [t_0d_np, t_1d_np, t_2d_np, t_3d_np]\n",
    "\n",
    "for ndt in numpy_defined_tensors:\n",
    "    print(tf.constant(ndt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types\n",
    "\n",
    "In general, using `np.array` (or `np.asarray`) is the recommended way of defining values for tensors by hand in TensorFlow. The primary reason for this is that you can specify the exact data type (`dtype`) you'd like the values to be represented with. For example, there's no way to specify a 32-bit integer vs a 64-bit integer with native Python. TensorFlow is tightly integrated with NumPy, and most TensorFlow data types have a corresponding NumPy `dtype`:\n",
    "\n",
    "TensorFlow type | Equivalent NumPy type | Description\n",
    "--- | --- | ---\n",
    "`tf.float32` | `np.float32` | 32 bit floating point.\n",
    "`tf.float64` | `np.float64` | 64 bit floating point.\n",
    "`tf.int8` | `np.int8` | 8 bit signed integer.\n",
    "`tf.int16` | `np.int16` | 16 bit signed integer.\n",
    "`tf.int32` | `np.int32` | 32 bit signed integer.\n",
    "`tf.int64` | `np.int64` | 64 bit signed integer.\n",
    "`tf.uint8` | `np.uint8` | 8 bit unsigned integer.\n",
    "`tf.string` | N/A | String type, as byte array\n",
    "`tf.bool` | `np.bool` | Boolean.\n",
    "`tf.complex64` | `np.complex64` | Complex number made of two 32 bit floating point numbers: real and imaginary parts.\n",
    "`tf.qint8` | N/A | 8 bit signed integer used in quantized Ops.\n",
    "`tf.qint32` | N/A | 32 bit signed integer used in quantized Ops.\n",
    "`tf.quint8` | N/A | 8 bit unsigned integer used in quantized Ops.\n",
    "\n",
    "Slightly modified version of [this table](https://www.tensorflow.org/versions/r0.12/resources/dims_types#data_types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to show that they are equivalent\n",
    "(tf.float32 == np.float32 and\n",
    " tf.float64 == np.float64 and\n",
    " tf.int8 == np.int8 and\n",
    " tf.int16 == np.int16 and\n",
    " tf.int32 == np.int32 and\n",
    " tf.int64 == np.int64 and\n",
    " tf.uint8 == np.uint8 and\n",
    " tf.bool == np.bool and\n",
    " tf.complex64 == np.complex64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary exception to when you should _not_ use `np.array()` is when defining a `Tensor` of strings. When using strings, just use standard Python lists. It's best practice to include the `b` prefix in front of strings to explicitly define the strings as byte-arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_string_tensor = [b\"first\", b\"second\", b\"third\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Shapes\n",
    "\n",
    "A common term in TensorFlow is a `Tensor` object's \"shape\". A shape value is a list or tuple containing an ordered set of integers. The _i_-th  element in the list describes the length of the _i_-th dimension in the tensor, while the number of elements in the list defines the dimensionality of the tensor. Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes corresponding to scalars\n",
    "# Note that either lists or tuples can be used\n",
    "s_0d_list = []\n",
    "s_0d_tuple = ()\n",
    "\n",
    "# Shape corresponding to a vector of length 3\n",
    "s_1d = [3]\n",
    "\n",
    "# Shape corresponding to a 2-by-3 matrix\n",
    "s_2d = (2, 3)\n",
    "\n",
    "# Shape corresponding to a 4-by-4-by-4 cube tensor\n",
    "s_3d = [4, 4, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `tf.shape` Operation to get the shape value of `Tensor` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note, np.ndarray.reshape takes its args \"flattened\" out\n",
    "#       (not in a list or tuple)\n",
    "arr = np.arange(24).reshape(2,3,4)\n",
    "print(\"In NumPy:\", arr.shape,arr,sep=\"\\n\")\n",
    "\n",
    "# tf.shape creates an Operation that returns a Tensor\n",
    "#          the returned Tensor is the shape of arr\n",
    "shape_op = tf.shape(arr)\n",
    "print(\"In TensorFlow:\", shape_op, sep=\"\\n\")\n",
    "\n",
    "shape = tf.Session().run(shape_op)\n",
    "print(\"Shape of tensor: \" + str(shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, defining an `Operation` doesn't *execute* it.  To execute it, we have to run it.  We do that with a helper `tf.Session`.  More to come below!  Quick quiz: is `shape_op` a 3D tensor or 1D tensor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow `Operation` Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow `Operation` objects (commonly abbreviated as \"Ops\" in the TensorFlow documentation) are nodes that perform compuation on or with Tensor objects. They take as input zero or more `Tensor` objects (or objects that can be converted into tensors- see the previous section), and output zero or more tensors. These outputs can then either be returned to the client or passed on to further Operations. Operations are the fundamental building blocks of any TensorFlow graph- their calculations represent nodes, and data flowing from one to the next represents edges.\n",
    "\n",
    "We've already seen a few `Operation` examples: `tf.add` and `tf.multiply` are classic examples: they both take in two tensors and output one. When given non-scalar values, they do addition/multiplication element-wise.  Also, `tf.constant` and `tf.shape` are `Operation`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize some arrays to be fed into tf.add as Tensors\n",
    "a = np.array([1, 2], dtype=np.int32)\n",
    "b = np.array([3, 4], dtype=np.int32)\n",
    "\n",
    "# tf.add creates an \"add\" Operation and places it in the graph\n",
    "# The variable c will be a handle to the output of the operation\n",
    "# This output can be passed on to other Operations!\n",
    "c = tf.add(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important thing to remember is that Operations do not execute when created - that's the reason `tf.add([1, 2],[3, 4])` doesn't return the value `[4, 6]` immediately. It must be passed into a `Session.run()` method, which we'll cover in more detail below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tf.Session().run(c)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or, since we're in a notebook, we can just evaluate the result\n",
    "# (without explicitly needing to print it out)\n",
    "# note: that the returned value is a numpy array\n",
    "tf.Session().run(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of the TensorFlow API is Operations.  In addition to Operation-specific inputs, each Operation can take in a `name` parameter, which can help identify Operations in TensorBoard and other tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.add(a, b, name=\"my_add_operation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting into the habit of adding names to your Operations now will save you headaches later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow `Graph` Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When TensorFlow is imported into Python, it automatically creates a `Graph` object and makes it the default graph. You can create more graphs as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new graph - constructor takes no parameters\n",
    "new_graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, operations (such as `tf.add` and `tf.multiply`) are added to the default graph when created. To add operations to your new graph, use a `with` statement along with the graph's `as_default()` method. This makes that graph the default while inside of the `with` block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with new_graph.as_default():\n",
    "    a = tf.add(3, 4)\n",
    "    b = tf.multiply(a, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default graph, other than being set to the default, is no different than any other `Graph`. If you need to get a handle to the default graph, use the `tf.get_default_graph` function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "default_graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: `get_default_graph()` will return whatever graph is set to the default, so if you are inside of a `with g.as_default()` block, `get_default_graph()` will return `g`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with new_graph.as_default():\n",
    "    print(new_graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Most TensorFlow models will not require more than one graph per script.*  So, often, you can simply use the default, implicit graph and be done. However, you may find multiple `Graph` instances useful when defining two independent models side-by-side. Additionally, there are mechanisms to export and import external models and load them in as `Graph` objects, which can allow you to feed the output of existing models into your new model (or vice versa). We won't be able to demonstrate these now, but see the TensorFlow API for more info: \n",
    "  * [`Graph.as_graph_def`](https://www.tensorflow.org/versions/r0.12/api_docs/python/framework/core_graph_data_structures#Graph.as_graph_def)\n",
    "  * [`tf.import_graph_def`](https://www.tensorflow.org/api_docs/python/tf/import_graph_def) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow `Session`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Sessions\n",
    "\n",
    "As we saw earlier, `Session` objects are used to launch and execute graphs. Earlier, we created a session using its default constructor, but it has three optional parameters:\n",
    "\n",
    "* `target` specifies the execution engine to use. By default it is the empty string, which causes the Session to use the standard local execution context. Typically, this parameter is only used when using TensorFlow in a distributed setting\n",
    "* `graph` specifies which `Graph` object the session should run. The default value is `None`, which causes the `Session` to load in the default graph. Sessions only manage one graph at a time, so executing more than one graph will require more than one session\n",
    "* `config` allows users to specify advanced options to configure the session. We won't cover this today, but some things that are available are: limiting the number of CPUs/GPUs used, logging options, and changing optimization of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A session with the default graph launched\n",
    "# Equivalent to: tf.Session(graph=tf.get_default_graph())\n",
    "sess_default = tf.Session()\n",
    "\n",
    "# A session with new_graph launched\n",
    "new_graph = tf.Graph()\n",
    "sess_new = tf.Session(graph=new_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Sessions\n",
    "\n",
    "The most important method of a `Session` is its `run()` function. Earlier in this notebook, we saw basic usage of the two primary parameters to `run()`: `fetches` and `feed_dict`.\n",
    "\n",
    "##### Retrieving information: `fetches`\n",
    "\n",
    "`fetches` expects a list of `Tensor` and/or `Operation` handles (or just a single `Tensor`/`Operation`). The list specifies what computations we would like TensorFlow to run, as well as what we'd like `run()` to output: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equiv:  tf.Session().run(tf.add(3,2))\n",
    "sess_default.run(tf.add(3,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow will only perform calculations necessary to compute the values specified in `fetches`, so it won't waste time if you only need to run a small part of a large, complicated graph.\n",
    "\n",
    "##### Sending information: `feed_dict`\n",
    "\n",
    "`feed_dict` is an optional parameter to `run`, but it becomes *required* when placeholder nodes are included. We saw it used to feed input data to placeholders, but `feed_dict` can actually send values to any node. The keys to the dictionary should be handles to `Tensor` objects (usually outputs of Operations), and the values should be replacement data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Operations, Tensors, etc (using the default graph)\n",
    "a = tf.add(3, 4)\n",
    "b = tf.multiply(a, 5)\n",
    "\n",
    "# Define a dictionary that says to replace the value of `a` with 15\n",
    "replacers = {a: 15}\n",
    "\n",
    "# Run the session without feed_dict\n",
    "# Prints (3 + 4) * 5 = 35\n",
    "print(sess_default.run(b))\n",
    "\n",
    "# Run the session, passing in `replace_dict` as the value to `feed_dict`\n",
    "# Prints 15 * 5 = 75 instead of 7 * 5 = 35\n",
    "print(sess_default.run(b, feed_dict=replacers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using placeholders,TensorFlow insists that any calls to `Session.run()` include `feed_dict` values for all placeholders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.int32, name=\"my_placeholder\")\n",
    "b = tf.add(a, 3)\n",
    "\n",
    "# This raises an error (with a LONG error message, so we \n",
    "# use try-except to catch it and print out just a portion)\n",
    "try:\n",
    "    sess_default.run(b)\n",
    "except tf.errors.InvalidArgumentError as e:\n",
    "    print(\"The error:\\n\", e.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.int32, name=\"my_placeholder\")\n",
    "b = tf.add(a, 3)\n",
    "\n",
    "# Create feed dictionary\n",
    "feed_dict = {a: 8}\n",
    "\n",
    "# Now it works!\n",
    "print(sess_default.run(b, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing out the Sessions we opened up\n",
    "sess_default.close()\n",
    "sess_new.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow `Variable` Objects\n",
    "\n",
    "The last fundamental TensorFlow class is the `Variable`. A TensorFlow `Variable` has persistent state across multiple calls to `Session.run()`, which means that learned parameters in machine learning models are Variables. We can create a Variable with a starting value of 0 like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_var = tf.Variable(0, name=\"my_var\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, even though the object has been created, the value of the `Variable` has to be initialized separately with either of the `tf.variables_initializer()` or, more commonly, `tf.global_variables_initializer()` Operations. Remember that Operations must be passed into `Session.run()` to be executed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having value initialization separated from object creation allows us to reinitialize the variable later if we'd like.\n",
    "\n",
    "*Note: `tf.global_variables_initializer()` used to be named `tf.initialize_all_variables()`, and `tf.variables_initializer()` used to be called `tf.initialize_variables()`.* These were renamed just before version 1.0.0 of TensorFlow, so if you follow older tutorials, you may need to update these functions.\n",
    "\n",
    "Now that the Variable is initialized, we can tweak it's value! Let's do some basic incrementing with the `Variable.assign()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "increment = my_var.assign(my_var + 1)\n",
    "\n",
    "for i in range(10):\n",
    "    print(sess.run(increment), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that if you run the previous code multiple times in the notebook (i.e., rerun the prior cell a few times in a row), the value persists and continues to climb. The Variable's state is maintained by the Session object, and the state will persist unless either the session is close, the Variable is re-initialized, or a new value is assigned to the Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize variables\n",
    "sess.run(init)\n",
    "\n",
    "# Start incrementing, beginning from 0 again\n",
    "for i in range(10):\n",
    "    print(sess.run(increment), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trainable Variables\n",
    "\n",
    "There are several optional parameters in the `Variable` constructor, but one to pay close attention to is `trainable`. It takes in a boolean value, which defaults to `True`, and specifies to TensorFlow whether the built-in optimization functions (which we will cover in a separate notebook) should affect this `Variable`. **If a `Variable` in you model should _not_ be adjusted during gradient descent, make sure to set its `trainable` parameter to `False`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 1\n",
    "Create a TensorFlow `Graph` that is based on the following image:\n",
    "\n",
    "<img src=\"./images/04.png\" width=70%/>\n",
    "\n",
    "[Use TensorFlow's API guide for math operations](https://www.tensorflow.org/api_guides/python/math_ops) to find Operations you don't know.  You'll want to look in the section called \"Reduction\".  If you are confused about how to give inputs to a reduction Operation, don't get too fancy.  Remember, a Python list (of Python lists/scalars *or* of `Tensor`s) can be used to create another input `Tensor`.\n",
    "\n",
    "##### Part 2\n",
    "\n",
    "Once you've created the graph, use a `Session` to run the graph and confirm the following input/output pairs:\n",
    "\n",
    "|In | Out|\n",
    "|---|----|\n",
    "|1, 2, 3| 14|\n",
    "|-1, -2, 3| 2|\n",
    "|123, 456, 789| 44669304 |\n",
    "\n",
    "##### Part 3\n",
    "Finally, use `tf.summary.FileWriter` to output the `Graph` to disk and double check that your model resembles the above image in TensorBoard (the image reads from left to right, TensorBoard displays them from bottom to top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TensorBoard](https://www.tensorflow.org/versions/r0.11/how_tos/summaries_and_tensorboard/index.html) is TensorFlow's built-in visualization software. With it, users can examine the error rate of models over time, debug their graphs, examine summary statistics, and compare various models with one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic steps to use TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without context, graphs that use TensorBoard summaries can seem cluttered and confusing. However, they are actually quite straightforward once you understand what each node is doing. Here are the basic steps you'll most commonly see:\n",
    "\n",
    "1. Pass the result of a `Tensor` you'd like to analyze to one of several [summary operations](https://www.tensorflow.org/api_guides/python/summary).\n",
    "2. Group all of your summaries together using [`tf.summary.merge_all()`](https://www.tensorflow.org/api_docs/python/tf/summary/merge_all) for convenience.\n",
    "3. Create a [`tf.summary.FileWriter`](https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter), which is responsible for writing summaries to disk.\n",
    "4. While training/evaluating, pass in the output of `tf.summary.merge_all()` to the `FileWriter`\n",
    "5. Once finished, start up TensorBoard in the terminal by using the built-in `tensorboard` command\n",
    "\n",
    "Let's start with a simple graph to get us going. The graph below simply takes in two `placeholder` inputs and performs addition, subtraction, multiplication, and division with them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly create the graph we're going to use\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    # Input placeholders\n",
    "    a = tf.placeholder(tf.float32, name=\"a\")\n",
    "    b = tf.placeholder(tf.float32, name=\"b\")\n",
    "    \n",
    "    # Perform +, -, *, and / operations\n",
    "    plus = tf.add(a, b, name=\"a_plus_b\")\n",
    "    minus = tf.subtract(a, b, name=\"a_minus_b\")\n",
    "    times = tf.multiply(a, b, name=\"a_times_b\")\n",
    "    divided = tf.divide(a, b, name=\"a_divided_by_b\")\n",
    "    \n",
    "    # Global step counter and its increment operation\n",
    "    global_step = tf.Variable(0, trainable=False, dtype=tf.int32, name=\"global_step\")\n",
    "    inc_step = tf.assign(global_step, global_step + 1, name=\"increment_step\")\n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty straightforward. We have two placeholder nodes, `a` and `b`, and then four Operations that take in `a` and `b` as input. For this exercise, we don't really _need_ to use a `tf.Variable` for `global_step`, but it's good to get in the habit of using this pattern. All of these nodes are placed in a `tf.Graph` object, `graph`.\n",
    "\n",
    "Now that we've constructed our graph, we can start up a `tf.Session`, initialize `global_step`, and run the graph. To keep things looking clean, we place all of the nodes we'd like to run into a list called `fetches` ahead of time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(graph=graph)\n",
    "sess.run(init) # don't forget to run init for our Variable!\n",
    "\n",
    "# Feed values for placeholders `a` and `b`\n",
    "a_val, b_val = 8.0, 4.0\n",
    "feed_dict = {a: a_val, b: b_val}\n",
    "fetches = [inc_step, plus, minus, times, divided]\n",
    "results = sess.run(fetches, feed_dict)\n",
    "\n",
    "# Print all results\n",
    "print(\"a: {} b: {}\".format(a_val, b_val))\n",
    "for i, result in enumerate(results):\n",
    "    print(\"{}: {}\".format(fetches[i].name[:-2], result))\n",
    "\n",
    "sess.close() # clean up the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring a Graph with TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get our first taste of TensorBoard. We'll add in some summaries in just a moment, but it's important to see that TensorBoard can be used to examine your graph with barely any extra effort. As mentioned above, the key class used to utilize TensorBoard is `tf.summary.FileWriter`, which takes in a string output directory as an input parameter. That is, you tell the `FileWriter` where to save files locally on disk. When creating a `FileWriter`, you can optionally pass in a `Graph` object, which will store a serialized version of the graph to disk, allowing you to explore your model graphically!\n",
    "\n",
    "If all you want to do is check out your graph, all you need to do is include these two lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('tbout/basic_ops', graph=graph)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a `FileWriter` and tells it to save information about our graph. Calling `close()` flushes any summaries that still need to be written to disk and closes the `FileWriter`. Since we aren't adding any summaries yet, we can immediately close the writer. Now, we should have a new directory inside the folder this notebook is located in called `basic_ops`. Navigate to the notebook directory inside your console and type the following:\n",
    "\n",
    "    $ tensorboard --logdir=tbout/basic_ops\n",
    "\n",
    "\n",
    "At first, you won't see much: the initial screen loaded is the \"Summaries\" tab, and we don't have any summaries (yet)! Click the \"Graph\" button at the top, and you should see a visual representation of our graph. Neat!\n",
    "\n",
    "Note:  If `tensorboard` doesn't automatically start up a browser window or tab in your current browser, simply create a new tab on your own and paste the URL to the right of the `at` from this line in the output: `Starting TensorBoard b'47' at http://0.0.0.0:6006`.  In this case, we would paste http://0.0.0.0:6006 into a new brower tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to modify our previous graph by adding in some summary operations. In this example, we'll use `tf.summary.scalar`, which creates a summary for a single (scalar) number. We'll make a new graph called `summary_graph` to store our new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly create the graph we're going to use\n",
    "summary_graph = tf.Graph()\n",
    "\n",
    "with summary_graph.as_default():\n",
    "    # Input placeholders\n",
    "    a = tf.placeholder(tf.float32, name=\"a\")\n",
    "    b = tf.placeholder(tf.float32, name=\"b\")\n",
    "\n",
    "    # Summaries for inputs\n",
    "    a_summ = tf.summary.scalar(\"a_input_summary\", a)\n",
    "    b_summ = tf.summary.scalar(\"b_input_summary\", b)\n",
    "    \n",
    "    # Perform +, -, *, and / operations\n",
    "    plus = tf.add(a, b, name=\"a_plus_b\")\n",
    "    minus = tf.subtract(a, b, name=\"a_minus_b\")\n",
    "    times = tf.multiply(a, b, name=\"a_times_b\")\n",
    "    divided = tf.divide(a, b, name=\"a_divided_by_b\")\n",
    "    \n",
    "    # Summaries for operations\n",
    "    plus_summ = tf.summary.scalar(\"plus_op_summary\", plus)\n",
    "    minus_summ = tf.summary.scalar(\"minus_op_summary\", minus)\n",
    "    times_summ = tf.summary.scalar(\"times_op_summary\", times)\n",
    "    divided_summ = tf.summary.scalar(\"divided_op_summary\", divided)\n",
    "    \n",
    "    # Global step counter and its increment operation\n",
    "    global_step = tf.Variable(0, trainable=False, dtype=tf.int32, name=\"global_step\")\n",
    "    inc_step = tf.assign(global_step, global_step + 1, name=\"increment_step\")\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    # Group all summaries together\n",
    "    merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we've added summaries for our inputs as well as our four different operations. At the very bottom (line 31 - hit Control-m followed by l (the letter L) in the code cell to see the line numbers), we've created a `tf.summary.merge_all()` operation, which bundles all of our summaries together into one operation. If we didn't use this, we'd have to run each of the summaries individually, which would get cumbersome.\n",
    "\n",
    "Now, as before, let's open a `Session`. We'll also open a `FileWriter` that points to the directory 'basic_summaries', but leave it open, as we're going to be writing summaries to disk with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use get_fresh_dir so that we can keep track of different\n",
    "# runs of our graph; here, it will creates directories like:\n",
    "# tbout/basic_summaries/1 \n",
    "# tbout/basic_summaries/2 \n",
    "# tbout/basic_summaries/3\n",
    "from helpers_01 import get_fresh_dir\n",
    "\n",
    "sess = tf.Session(graph=summary_graph)\n",
    "writer = tf.summary.FileWriter(get_fresh_dir('tbout/basic_summaries'), \n",
    "                               graph=summary_graph)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to create 20 random samples to generate some toy data. For each sample, we get a random number between 0-25 for both `a` and `b`, and then run our graph with those random numbers as input. When we run `merged`, our `merge_all` op, `sess.run()` outputs a summary object which we can pass into our `SummaryWriter`. We do this by calling `writer.add_summary`, which takes in a summary object and (optionally) a `global_step` parameter.\n",
    "\n",
    "Notice that instead of creating a `fetches` list as we did above, we're only calling the `merge_all` operation. Because we don't need to use the output from the model and the summaries depend on the output nodes in order to be calculated, we can simply call the `merged` op to implicitly run each of our addition, subtraction, multiplication, and division nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    rand_a = random.uniform(0, 25)\n",
    "    rand_b = random.uniform(0, 25)\n",
    "    feed_dict = {a: rand_a, b: rand_b}\n",
    "    step, summaries = sess.run([inc_step, merged], feed_dict=feed_dict)\n",
    "    writer.add_summary(summaries, global_step=step)\n",
    "    writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we're done running our graph, we can close out our `Session` and `FileWriter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check out our summaries! Start up TensorBoard, pointing to the \"basic_summaries\" directory:\n",
    "\n",
    "    $ tensorboard --logdir=tbout/basic_summaries\n",
    "\n",
    "\n",
    "We'll be using and discussing TensorBoard throughout the class, but you can check out [its documentation here](https://www.tensorflow.org/get_started/summaries_and_tensorboard)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 1\n",
    "\n",
    "Examine the following code. Using pen/paper or a whiteboard, draw the computation graph you think is the result of running this code in TensorFlow.\n",
    "\n",
    "Remember that the Python variable handles (in this case, the variables `a` and `b`) are simply pointers to underlying `Operation` or `Tensor` objects, and assigning them a new `Operation` or `Tensor` doesn't change/modify the original `Tensor`.\n",
    "\n",
    "To check your answer, start up TensorBoard on `tbout/01_lab21` and look at the displayed `Graph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2 = tf.Graph()\n",
    "with graph_2.as_default():\n",
    "    a = tf.placeholder(tf.float32, name='input')\n",
    "    b = a\n",
    "    for i in range(5):\n",
    "        b = tf.add(a, b)\n",
    "\n",
    "writer = tf.summary.FileWriter('tbout/01_lab21', graph=graph_2)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 2\n",
    "\n",
    "Revisit the graph you made in [Exercise 1](http://localhost:8888/notebooks/01_tensorflow_fundamentals.ipynb#Exercise-1).  Use a `tf.summary.FileWriter` to output the `Graph` to disk (use the directory `tbout/01_lab22`).  Double check that your model resembles the image you used to design the graph.  The image is aligned from left to right, TensorBoard displays the graph from bottom to top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code in the cell for Part 1 and then view the graph with:\n",
    "  * shell: `$ tensorboard --logdir=tbout/01_lab21`\n",
    "  * open a browser tab:  http://0.0.0.0:6006 (or similar)\n",
    "  * Click on the Graph tab at the top of the page    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And view the graph with:\n",
    "  * shell: `$ tensorboard --logdir=tbout/01_lab22`\n",
    "  * browser tab:  http://0.0.0.0:6006\n",
    "  * Click on the Graph tab at the top of the page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizing graphs with `tf.name_scope()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice that the graph is starting to get a little bit more complicated. As we start building more complex models, it's going to be important that we keep our code organized, or else it will be impossible to discern what is going on when we load up TensorFlow. Luckily, TensorFlow provides functionality to help you keep your code organized cleanly- the most basic of which is [`tf.name_scope()`](https://www.tensorflow.org/api_docs/python/tf/name_scope). Simply use this function with a `with` statement to break your code up into labeled \"sections\".\n",
    "\n",
    "```python\n",
    "with tf.name_scope('my_section'):\n",
    "    # Place some ops indented here\n",
    "    ...\n",
    "```\n",
    "```python\n",
    "with tf.name_scope('another_section'):\n",
    "    # Place ops related to something else here\n",
    "    ...\n",
    "```\n",
    "\n",
    "Let's add some name scopes to our last `Graph` to see how they help us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly create the graph we're going to use\n",
    "organized_graph = tf.Graph()\n",
    "\n",
    "with organized_graph.as_default():\n",
    "    with tf.name_scope('inputs'):\n",
    "        a = tf.placeholder(tf.float32, name=\"a\")\n",
    "        b = tf.placeholder(tf.float32, name=\"b\")\n",
    "\n",
    "    with tf.name_scope('input_summaries'):\n",
    "        a_summ = tf.summary.scalar(\"a_input_summary\", a)\n",
    "        b_summ = tf.summary.scalar(\"b_input_summary\", b)\n",
    "    \n",
    "    with tf.name_scope('operations'):\n",
    "        plus = tf.add(a, b, name=\"a_plus_b\")\n",
    "        minus = tf.subtract(a, b, name=\"a_minus_b\")\n",
    "        times = tf.multiply(a, b, name=\"a_times_b\")\n",
    "        divided = tf.divide(a, b, name=\"a_divided_by_b\")\n",
    "    \n",
    "    with tf.name_scope('op_summaries'):\n",
    "        plus_summ = tf.summary.scalar(\"plus_op_summary\", plus)\n",
    "        minus_summ = tf.summary.scalar(\"minus_op_summary\", minus)\n",
    "        times_summ = tf.summary.scalar(\"times_op_summary\", times)\n",
    "        divided_summ = tf.summary.scalar(\"divided_op_summary\", divided)\n",
    "    \n",
    "    with tf.name_scope('global_step'):\n",
    "        global_step = tf.Variable(0, trainable=False, dtype=tf.int32, name=\"global_step\")\n",
    "        inc_step = tf.assign(global_step, global_step + 1, name=\"increment_step\")\n",
    "    \n",
    "    with tf.name_scope('helpers'):\n",
    "        init = tf.global_variables_initializer()\n",
    "        merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we simply added different sections to our existing code, which provides a nice form of self-documentation. Now we can run it, placing our summaries into a new directory, `tbout/organized_summaries`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(graph=organized_graph)\n",
    "writer = tf.summary.FileWriter(get_fresh_dir('tbout/organized_summaries'), \n",
    "                               graph=organized_graph)\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(20):\n",
    "    rand_a = random.uniform(0, 25)\n",
    "    rand_b = random.uniform(0, 25)\n",
    "    feed_dict = {a: rand_a, b: rand_b}\n",
    "    step, summaries = sess.run([inc_step, merged], feed_dict=feed_dict)\n",
    "    writer.add_summary(summaries, global_step=step)\n",
    "    writer.flush()\n",
    "\n",
    "writer.close()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As before, we can look at the results with:\n",
    "\n",
    "    tensorboard --logdir=tbout/organized_summaries`]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Revisit the graph you made in [Exercise 1](http://localhost:8888/notebooks/01_tensorflow_fundamentals.ipynb#Exercise-1).  Modify it to include the following features:\n",
    "  1. Name scopes around the first, second, and third \"layers\" \n",
    "    * These are the inputs, multiplication/product nodes, and sum nodes, respectively.\n",
    "  2. A global step `Variable` to keep track of number of runs\n",
    "  3. A `Variable` that keeps a running sum of the outputs.  It should have an [assign Op](https://www.tensorflow.org/api_docs/python/tf/assign) that adds itself to the (current) sum of outputs.\n",
    "  4. Add `Summaries` for the input nodes, final output node, and the running sum Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build the Model in a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the Model and Gather Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
